{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "38e28362-49bd-4f24-83c7-e0aec1bd63c3",
     "showTitle": true,
     "title": "Install Dependencies"
    },
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "%pip install mlflow==2.10.1 langchain==0.1.5 databricks-vectorsearch==0.22 databricks-sdk==0.18.0 mlflow[databricks] pyspark\n",
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b067e838-75f7-48ed-a764-8319c3d29b96",
     "showTitle": true,
     "title": "Set needed parameters"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "host = \"https://\" + spark.conf.get(\"spark.databricks.workspaceUrl\")\n",
    "os.environ['DATABRICKS_TOKEN'] = dbutils.secrets.get(scope=\"hackathon-databricks\", key=\"hackathon-databricks\")\n",
    "\n",
    "index_name=\"databricks_hackathon.llm.docs_idx\"\n",
    "host = \"https://\" + spark.conf.get(\"spark.databricks.workspaceUrl\")\n",
    "\n",
    "VECTOR_SEARCH_ENDPOINT_NAME=\"rag_demo\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f14965e2-7cce-4244-97d6-dd75fb315268",
     "showTitle": true,
     "title": "Build Retriever"
    }
   },
   "outputs": [],
   "source": [
    "from databricks.vector_search.client import VectorSearchClient\n",
    "from langchain_community.vectorstores import DatabricksVectorSearch\n",
    "from langchain_community.embeddings import DatabricksEmbeddings\n",
    "\n",
    "embedding_model = DatabricksEmbeddings(endpoint=\"bge_small_en_v1_5\")\n",
    "\n",
    "def get_retriever(persist_dir: str = None):\n",
    "    os.environ[\"DATABRICKS_HOST\"] = host\n",
    "    #Get the vector search index\n",
    "    vsc = VectorSearchClient(workspace_url=host, personal_access_token=os.environ[\"DATABRICKS_TOKEN\"])\n",
    "    vs_index = vsc.get_index(\n",
    "        endpoint_name=VECTOR_SEARCH_ENDPOINT_NAME,\n",
    "        index_name=index_name\n",
    "    )\n",
    "\n",
    "    # Create the retriever\n",
    "    vectorstore = DatabricksVectorSearch(\n",
    "        vs_index, text_column=\"text\", embedding=embedding_model\n",
    "    )\n",
    "    return vectorstore.as_retriever()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0d5f7ce3-8a38-4b20-be39-e5688af79f30",
     "showTitle": true,
     "title": "Create the RAG Langchain"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NOTICE] Using a Personal Authentication Token (PAT). Recommended for development only. For improved performance, please use Service Principal based authentication. To disable this message, pass disable_notice=True to VectorSearchClient().\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:langchain_community.vectorstores.databricks_vector_search:embedding model is not used in delta-sync index with Databricks-managed embeddings.\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_community.chat_models import ChatDatabricks\n",
    "\n",
    "chat_model = ChatDatabricks(endpoint=\"dbrx_instruct_v3\", max_tokens = 200)\n",
    "\n",
    "TEMPLATE = \"\"\"You are an assistant for insurance comparison depending on the physical assets of the properties provided by user. You are answering how to compare the data between the properties and compare between the insurance policies and let us know which will be the best insurance to go with depending on the physical asset information passed by the user queries. If the question is not related to one of these topics, kindly decline to answer. If you don't know the answer, just say that you don't know, don't try to make up an answer. If the question appears to be for an appliance you don't have data on, say so.  Keep the answer as concise as possible.  Provide all answers only in English.\n",
    "Use the following pieces of context to answer the question at the end:\n",
    "{context}\n",
    "Question: {question}\n",
    "Answer:\n",
    "\"\"\"\n",
    "prompt = PromptTemplate(template=TEMPLATE, input_variables=[\"context\", \"question\"])\n",
    "\n",
    "chain = RetrievalQA.from_chain_type(\n",
    "    llm=chat_model,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=get_retriever(),\n",
    "    chain_type_kwargs={\"prompt\": prompt}\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a5e5ce23-cbed-4945-8cbf-f924d005e5ce",
     "showTitle": true,
     "title": "Test Langchain"
    }
   },
   "outputs": [],
   "source": [
    "question = {\"query\": \"Insurance issued\"}\n",
    "answer = chain.run(question)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "63b89a9d-32e0-482a-a6a7-7fb13e02c1ec",
     "showTitle": true,
     "title": "Register our Chain as a model to Unity Catalog"
    }
   },
   "outputs": [],
   "source": [
    "from mlflow.models import infer_signature\n",
    "import mlflow\n",
    "import langchain\n",
    "\n",
    "mlflow.set_registry_uri(\"databricks-uc\")\n",
    "model_name = \"databricks_hackathon.llm.insurance_model\"\n",
    "\n",
    "with mlflow.start_run(run_name=\"insurance_comparison_assistant\") as run:\n",
    "    signature = infer_signature(question, answer)\n",
    "    model_info = mlflow.langchain.log_model(\n",
    "        chain,\n",
    "        loader_fn=get_retriever,  # Load the retriever with DATABRICKS_TOKEN env as secret (for authentication).\n",
    "        artifact_path=\"chain\",\n",
    "        registered_model_name=model_name,\n",
    "        pip_requirements=[\n",
    "            \"mlflow==\" + mlflow.__version__,\n",
    "            \"langchain==\" + langchain.__version__,\n",
    "            \"databricks-vectorsearch\",\n",
    "        ],\n",
    "        input_example=question,\n",
    "        signature=signature\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "rag_chain_agent_model",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
